{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "directorio = f\"./DATA/asistente_2\"\n",
    "pdf_files = [f for f in os.listdir(directorio) if f.endswith('.pdf')]\n",
    "documentos = []\n",
    "for pdf_file in pdf_files:\n",
    "    ruta_pdf = os.path.join(directorio, pdf_file)\n",
    "    loader = PyPDFLoader(ruta_pdf)\n",
    "    documentos.extend(loader.load())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "\n",
    "chunks = text_splitter.split_documents(documentos)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adm_hlopez\\AppData\\Local\\Temp\\ipykernel_10408\\1394854328.py:16: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import shutil\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "CHROMA_PATH = \"CHROMA/asistente_2\"\n",
    "\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "        chunks, embedding_function, persist_directory=CHROMA_PATH\n",
    "    )\n",
    "\n",
    "db.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adm_hlopez\\AppData\\Local\\Temp\\ipykernel_10408\\244422769.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n"
     ]
    }
   ],
   "source": [
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31. El uso aceptable, según el contexto proporcionado, se refiere a la utilización de manera autorizada y en estricta conformidad con las políticas y normativas de seguridad de la institución, con el fin de preservar la integridad, confidencialidad y disponibilidad de la información.\n",
      "\n",
      "32. El propietario del activo de información corresponde al responsable de tomar decisiones respecto del activo. Esto no implica necesariamente derecho de propiedad sobre el activo de información.\n",
      "\n",
      "---\n",
      "\n",
      "• Definir los procesos de gestión y cambios correspondiente a los activos de información se refiere a establecer procedimientos para administrar y modificar los activos de información críticos en la Subsecretaría, según sea indicado por las jefaturas de cada área.\n",
      "• Definir el uso aceptable del activo de la información tanto como a los funcionarios/as como a las partes interesadas se refiere a establecer normas y reglas para la utilización autorizada de los activos de información críticos por parte de los funcionarios/as y otras personas interesadas en la Subsecretaría.\n",
      "\n",
      "---\n",
      "\n",
      "2. ALCANCE: Esta política aplica a todos los activos de información críticos que serán indicados por las jefaturas de cada área en la Subsecretaría, correspondientes a los procesos de provisión.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "query_text=\"que se entiende por uso aceptable\"\n",
    "\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "#print(results)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Responde la pregunta basandote solo en el siguiente contexto:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Responde la pregunta basandote en el contexto de arriba: {question}\n",
    "\"\"\"\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "#print(prompt)\n",
    "model = ChatOllama(model=\"mistral\",temperature=0,stream=True)\n",
    "response_text = model.predict(prompt)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "rephrase_template = \"\"\"Dada la siguiente conversación y una pregunta de seguimiento, reformule la pregunta de seguimiento para que sea una pregunta independiente, en su idioma original..\n",
    "\n",
    "Historial de chat:\n",
    "{chat_history}\n",
    "Entrada de seguimiento: {question}\n",
    "Pregunta independiente:\"\"\"\n",
    "\n",
    "REPHRASE_TEMPLATE = PromptTemplate.from_template(rephrase_template)\n",
    "rephrase_chain = REPHRASE_TEMPLATE | ChatOllama(model=\"mistral\",temperature=0) | StrOutputParser()\n",
    "\n",
    "template = \"\"\"Como un asistente virtual del Ministerio de energia, \n",
    "Responda la pregunta  basándose únicamente en el siguiente contexto.:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | ANSWER_PROMPT\n",
    "    | ChatOllama(model=\"mistral\",temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_chain = rephrase_chain | retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Lo siento! El contexto proporcionado no contiene información sobre la capital de Francia.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"cual es la capital de francia\",\n",
    "        \"chat_history\": [\n",
    "           \n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
