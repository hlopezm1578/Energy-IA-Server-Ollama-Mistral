{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader,PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage, HumanMessage,SystemMessage\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "import redis\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = f\"./DATA\"\n",
    "pdf_files = [f for f in os.listdir(directorio) if f.endswith('.pdf')]\n",
    "documentos = []\n",
    "for pdf_file in pdf_files:\n",
    "    ruta_pdf = os.path.join(directorio, pdf_file)\n",
    "    loader = PyPDFLoader(ruta_pdf)\n",
    "    documentos.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "chunks = text_splitter.split_documents(documentos)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adm_hlopez\\AppData\\Local\\Temp\\ipykernel_10508\\3162101344.py:4: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  vectorstore = PGVector(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e3cc5731-f3ef-44c9-99ec-cfa8ce85f8c7',\n",
       " '735b66ce-0060-4c08-979d-fda914e24857',\n",
       " 'f7ace327-6591-4a25-9cc5-eb12ec313de9',\n",
       " '1481d248-889e-416c-a675-7052f61ae4b3',\n",
       " '0aed602a-bdac-4522-bbf1-09101fa069a8',\n",
       " '43a73d16-9cb7-418f-8758-d8289c6d465e',\n",
       " '7483bb6f-5fb2-4aed-8203-646c9245c213',\n",
       " '8855026a-00c7-4f87-a978-27626dd15788',\n",
       " 'f50bf9f4-3630-4ea2-b1a3-d1a36cefe08d',\n",
       " '352c56ef-4505-4d98-9315-aa7392c93f5a',\n",
       " '250c0500-90e9-4a44-b411-b2f9cb9703d8',\n",
       " '0d3e31ca-9328-49b9-8613-f86b53f9b24b',\n",
       " 'c96b53ea-1fb0-4e55-b878-78431b9c767c',\n",
       " 'e5ea47f0-b1f9-48f9-b20e-bbd11a8cc4ca',\n",
       " '059b6871-16d9-446f-a875-1a02918b282f',\n",
       " '69cd0f0f-6923-4f61-95d2-2fc53ea98d8e',\n",
       " '614f6e8f-f623-4ab4-a9f3-92d65d25e0a3',\n",
       " 'c79c6421-b285-4796-93d4-e5188cd3113c',\n",
       " 'e4d376bd-c2ce-4969-ab45-e7b5f2990697',\n",
       " '80719f80-821d-4961-98d6-36cd47be3a7f',\n",
       " '0c46b75d-511e-466d-bcaf-7f5519ed6a77',\n",
       " '77f8f1c6-df87-41fc-80ff-aed0ccbffcb5',\n",
       " '93b3ecf8-4e0f-487b-9768-8c935227bcae',\n",
       " '9e54bcbb-b7df-456e-b5a3-66ce805de0b5',\n",
       " '0a90025e-b0d4-466f-8225-8981c8881163',\n",
       " '2ccceb61-e846-4c26-910d-420f5b5f4433',\n",
       " '0fa5f39f-959f-44b9-b691-5e32c62d9c92',\n",
       " '77f13179-7aea-4115-8cc3-365fa5326ec9',\n",
       " '37fa8779-1957-4572-829a-ffd0bb257c96',\n",
       " 'd76a532b-100a-4c0d-a809-1e03bcd96486',\n",
       " 'acac966e-621e-43cb-ae81-cf8e484a60f1',\n",
       " 'd5c187fb-35be-433b-a774-c30a1627047d',\n",
       " 'df734920-4e47-4429-b03c-423a780749cf',\n",
       " '124ab368-61fb-40f6-a19e-cb3008c2207e',\n",
       " '124ef97e-0a4b-4bfe-878f-25bd9a8a5c23',\n",
       " '22e6b117-85fe-4f27-b7a5-27f689d46087',\n",
       " 'e175a7c9-e88a-4a29-8495-92fa845e2044',\n",
       " '30f0c680-547f-4f68-8f88-710b1f2a0c73',\n",
       " 'b54e6559-0006-47af-aa6a-542ad35991b8',\n",
       " 'af99e22c-606f-46cf-942e-334a504b0f26',\n",
       " '4ce178ba-5aba-450c-bf61-b1a860b13588',\n",
       " '05bc836d-1282-456c-8d79-2c647b5fad15',\n",
       " 'ae2d697f-eca8-42e2-ad45-4ea8da5eaa89',\n",
       " 'af43a269-1512-4cf5-a780-24750bb0f61f',\n",
       " '88457e08-1f02-4e25-a6db-e10957c49953',\n",
       " 'd06d080f-b640-4e16-89bf-da281115ba58',\n",
       " 'c3cd9c74-8f3c-4bf9-9c24-ca9f3c03ee03',\n",
       " 'dcfa92ae-3e78-4113-83b4-200b2a95300c',\n",
       " '0f75cfaf-f857-491d-9eaf-356180a5a1c9',\n",
       " '24b653bb-4906-4649-84a9-89ac3e7aead4',\n",
       " '851859eb-6648-4ef8-97fd-7e6b7de34f66',\n",
       " '99674ddd-ada8-4165-9794-3d06a87b3ff8',\n",
       " '6bab82a2-b962-4186-93d9-4275bb96eda7',\n",
       " '9163d1b3-f1fe-4274-aba4-38d5aba32f8f',\n",
       " '87aed5a0-85d6-48d5-a236-074a36694cc8',\n",
       " '7e327e4e-5023-4080-9bde-f80769885cad',\n",
       " 'de8dbcea-172c-474f-b001-967eaa7e6ac7',\n",
       " '828485f8-ec7f-4e48-98da-88831e72a5a5',\n",
       " 'ca25b0f9-8590-4b99-91d2-0cb64f3aee6d',\n",
       " 'aca7fd96-df48-423c-943f-4cd701f1cd49',\n",
       " '27b8c984-4cd2-4693-ac41-b8725bfaa131',\n",
       " '3b6fbe75-a737-4d3b-a000-974a9e4e81df']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://admin:admin@127.0.0.1:5433/vectordb\"\n",
    "COLLECTION_NAME = f\"vectordb_2\"\n",
    "vectorstore = PGVector(\n",
    "connection_string=CONNECTION_STRING,\n",
    "embedding_function=embedding_function,\n",
    "collection_name=COLLECTION_NAME,\n",
    ")\n",
    "vectorstore.add_documents(chunks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 2496.31it/s]\n"
     ]
    }
   ],
   "source": [
    "class Utf8TextLoader(TextLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['encoding'] = 'utf-8'\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"./DATA\", glob=\"**/*.txt\", loader_cls=Utf8TextLoader, show_progress=True\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hlope\\AppData\\Local\\Temp\\ipykernel_45884\\3365957905.py:6: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  vectorstore = PGVector(\n"
     ]
    }
   ],
   "source": [
    "#embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://admin:admin@127.0.0.1:5433/vectordb\"\n",
    "COLLECTION_NAME = \"vectordb_3\"\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=COLLECTION_NAME,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7f633153-c3c3-4bed-95d2-b52e766fba20',\n",
       " 'fcd97243-a50e-4de7-8fb7-1884253761c8',\n",
       " '5fbfa1f9-2835-4b62-8034-27d36073569f',\n",
       " '345ff690-80d9-428c-838b-91ea837a33c6',\n",
       " '567bf6bf-b466-44c9-b5f1-9539244ee479',\n",
       " 'a6ed9c86-aac6-411e-9ced-889257bd15c4',\n",
       " '252b6062-14e0-4cd6-abe0-b1fe72a17fa5',\n",
       " 'd2306e37-7dca-4b05-bcb6-83db3dbcad01',\n",
       " 'a75110f3-566d-46df-b242-f1fcba6b476b',\n",
       " '12d9baa5-ae40-4b5f-b6c8-e045cb8e8d0d',\n",
       " '207c9927-9f8b-4d88-a674-b26578a0c853',\n",
       " '1db21720-6690-4b56-8d88-eb92e25db7b6',\n",
       " '4efe6d47-9457-48e7-bc39-f24d8a7fd929',\n",
       " '257027de-129f-47c3-ba46-68991ec1a958',\n",
       " '0662c114-8638-491b-b61a-f89b54c1522c',\n",
       " 'b985db85-5fad-49cf-97cb-ec4ff80880ad',\n",
       " '780e5f97-82cd-44d0-8ea5-d1e780ff587b',\n",
       " '40627cb3-ba86-4d55-8621-ffae7ae3d00b',\n",
       " 'b0534ffb-b1d9-407b-b482-02204a3a8029',\n",
       " '9d4b8144-8362-4a66-b3c5-463f2b64d8ea',\n",
       " '29c37dd5-1a38-4a6b-beaa-18c435405aef',\n",
       " '19c77644-51e2-4ad8-9d57-db0be5fa98c0',\n",
       " '361a8ba5-113b-4afc-9469-1a4c2731af36',\n",
       " '65f0900a-f142-4c01-8c71-6e89670abbb6',\n",
       " '7feb924e-6d78-48b3-a9aa-61d517694868',\n",
       " 'e62b62ce-ad16-481f-9950-5a0ea245c8df',\n",
       " '55f7fc9c-76a4-4991-86e1-0b6fc13e4eb2',\n",
       " 'eabf8d92-21e7-47ef-afca-69b74ba33b59',\n",
       " '2e47255c-8823-4bb1-9b77-738a5d62c901',\n",
       " '33dc2a2d-1bf4-4089-9d47-b7c4e1f76197',\n",
       " 'de5a4e03-add9-42bb-aa69-846c5b2f8b22',\n",
       " 'ff9e6884-7d76-4f13-873d-990bc759d7b3',\n",
       " '70a903aa-7531-49b4-b417-361665b20223']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in 'langchain_pg_embedding': 0\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "TABLE_NAME = \"langchain_pg_embedding\"\n",
    "CONN_STRING = \"dbname='vectordb' user='admin' host='127.0.0.1' port='5433' password='admin'\"\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = f\"SELECT COUNT(*) FROM {TABLE_NAME};\"\n",
    "\n",
    "cur.execute(query)\n",
    "row_count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"Total rows in '{TABLE_NAME}': {row_count}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted all rows from 'langchain_pg_embedding'\n"
     ]
    }
   ],
   "source": [
    "delete_query = f\"DELETE FROM {TABLE_NAME};\"\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cur = conn.cursor()\n",
    "cur.execute(delete_query)\n",
    "conn.commit()\n",
    "print(f\"Deleted all rows from '{TABLE_NAME}'\")\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'DATA\\\\preguntas.txt'}, page_content='¿Cuáles son los principales beneficios de Bienestar? Al ser asociado(a) al Servicio de Bienestar contarás tú como asociado(a) y tus cargas legales con un Seguro complementario de Salud, vida y catastrófico , que actualmente está adjudicado por la compañía de seguros BCI, también podrás tener múltiples beneficios como: solicitud de préstamos a tasas preferenciales, bonos de nacimiento, matrimonio, etc., solicitud de reembolsos dentales, médicos, y también podrás acceder a diversos beneficios con'),\n",
       " Document(metadata={'source': 'DATA\\\\preguntas.txt'}, page_content='p:¿Cuáles son los beneficios del Seguro Complementario de Salud de BCI Seguros?'),\n",
       " Document(metadata={'source': 'DATA\\\\preguntas.txt'}, page_content='Para mayor información de cómo utilizar adecuadamente sus beneficios y requisitos, o enviar sugerencias, puede escribirnos al correo  bienestar@minenergia.cl'),\n",
       " Document(metadata={'source': 'DATA\\\\beneficios.txt'}, page_content='Beneficio dental\\nSe mantiene beneficio dental reembolsado directamente por Bienestar, correspondiente al 50% del monto gastado con un tope anual de $ 325.000.- por grupo familiar.\\nEste beneficio es exclusivo para las prestaciones dentales que realice el funcionario o sus cargas familiares.\\nRequisitos: Debe presentar solicitud de beneficios, adjuntando presupuesto y boleta del profesional o del centro dental. Plazo de presentación en Bienestar 6 meses desde la fecha de la atención dental.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"que beneficios hay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model=\"deepseek-r1:7b\",temperature=0,stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_template = \"\"\"Dada la siguiente conversación y una pregunta de seguimiento, reformule la pregunta de seguimiento para que sea una pregunta independiente, en su idioma original..\n",
    "\n",
    "Historial de chat:\n",
    "{chat_history}\n",
    "Entrada de seguimiento: {question}\n",
    "Pregunta independiente:\"\"\"\n",
    "\n",
    "REPHRASE_TEMPLATE = PromptTemplate.from_template(rephrase_template)\n",
    "rephrase_chain = REPHRASE_TEMPLATE | chat | StrOutputParser()\n",
    "\n",
    "template = \"\"\"Como un asistente de atencion al cliente, \n",
    "Responde la pregunta lo mas precisa posible basándose únicamente en el siguiente contexto:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | ANSWER_PROMPT\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_chain = rephrase_chain | retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, let me break down how I approached this query.\\n\\nFirst, the user provided a context with several documents in Spanish, each addressing different questions related to benefits and payments. The main points are about additional payments for charges, rejections, apelling, and the time frame for requesting refunds.\\n\\nThe user\\'s initial question was \"¿Cómo se envian los gastos médicos al seguro para su rembolso?\" which translates to asking how medical expenses are sent to the insurance for refunds. My task is to rephrase this into an independent question in Spanish.\\n\\nI considered making it more natural by changing the structure from \"como se envían\" to something like \"¿Cómo se realizan los pagos de gastos médicos?\" This keeps the core of the question intact while using a different phrasing that sounds more conversational and direct.\\n\\nI also made sure the question is specific, focusing on the process or method used for sending medical expenses, which aligns with what the user is asking for.\\n</think>\\n\\nPregunta independiente: ¿Cómo se realizan los pagos de gastos médicos al seguro para su rembolso?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"como se envian los gastos medicos\",\n",
    "        \"chat_history\": [\n",
    "           \n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_CLASS_MAP = {\n",
    "    \"asistente\": AIMessage,\n",
    "    \"usuario\": HumanMessage,\n",
    "    \"system\": SystemMessage\n",
    "}\n",
    "\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    conversation: List[Message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\n",
    "        \"question\": \"que beneficios hay\",\n",
    "        \"chat_history\": [\n",
    "           \n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n",
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique event types: {'on_parser_stream', 'on_chat_model_stream', 'on_prompt_start', 'on_chain_stream', 'on_chain_end', 'on_chat_model_start', 'on_parser_end', 'on_retriever_end', 'on_parser_start', 'on_retriever_start', 'on_prompt_end', 'on_chain_start'}\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "async for event in final_chain.astream_events(message, version=\"v1\"):\n",
    "    events.append(event)\n",
    "event_types = {event[\"event\"] for event in events}\n",
    "print(\"Unique event types:\", event_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream started...\n",
      "<think>\n",
      "Alright, let me break down how I arrived at that answer. The user provided a conversation history where they asked about the benefits available, and now they want to follow up with a specific question.\n",
      "\n",
      "First, I need to understand what the user is asking for. They want to reformulate an entrance into a standalone question in Spanish. The original entrance was \"que beneficios hay,\" which translates to \"what are the benefits.\" To make this a more precise independent question, I added \"en general\" (in general) to specify that they're asking about the benefits available.\n",
      "\n",
      "So, the final answer is:  \n",
      "¿Cuáles son los beneficios en general?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "async for event in  final_chain.astream_events(message, version=\"v1\"):\n",
    "    #print(event)\n",
    "    if event[\"event\"] == \"on_chat_model_start\":\n",
    "        print(\"Stream started...\", flush=True)\n",
    "        count+=1\n",
    "    elif event[\"event\"] == \"on_chat_model_stream\" and count>1:\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, let me break down how I approached this query:\n",
      "\n",
      "1. **Understanding the Context**: The user provided a conversation history where they asked about benefits related to the \"Bienestar\" program.\n",
      "\n",
      "2. **Identifying the Need**: They want to follow up by asking an independent question in Spanish without relying on context from previous messages.\n",
      "\n",
      "3. **Formulating the Question**: I translated the request into a standalone question: \"¿Cuáles son los beneficios?\" which means \"What are the benefits?\"\n",
      "\n",
      "4. **Ensuring Clarity and Politeness**: The question is clear, polite, and covers all possible benefits without assuming how many there might be.\n",
      "\n",
      "5. **Providing the Answer**: I included both the Spanish and English versions of the response to ensure clarity for the user.\n",
      "\n",
      "This approach ensures that the follow-up question is precise, natural, and meets the user's requirements effectively."
     ]
    }
   ],
   "source": [
    "async for chunk in final_chain.astream(message):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'asistente', 'content': 'Hola, ¿en que puedo ayudarlo?'}, {'role': 'usuario', 'content': 'como se envian los gastos medicos'}, {'role': 'asistente', 'content': '1. Llevar el formulario del seguro al médico o dentista para que llene los datos solicitados, como por ejemplo: el diagnóstico y los procedimientos asociados al diagnóstico.<br>2. En situaciones especiales no es necesario que el formulario sea llenado por el médico, como en el caso de una continuación de un tratamiento o una atención de urgencia.<br>3. Detalles sobre los porcentajes de reembolso según la prestación médica realizada no se especifican en el contexto proporcionado.<br>4. Algunas prestaciones como consultas médicas y exámenes, la cobertura aplica automáticamente por I-med (no siempre, hay que fijarse en el bono), por eso se recomienda siempre andar con el formulario, para solicitar el reembolso en caso de que I-med no lo realice en línea.<br>5. No se especifica cómo se realizan las transferencias de gastos médicos en el contexto proporcionado.'}, {'role': 'usuario', 'content': 'cuale son  porcentajes de reembolso'}, {'role': 'asistente', 'content': ' En el contexto proporcionado, no hay información específica sobre los porcentajes de reembolso que se aplican en este caso. Los porcentajes de reembolso dependen de la prestación médica realizada y están detallados en un documento diferente.'}]\n"
     ]
    }
   ],
   "source": [
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "existing_conversation_json = r.get(\"_p9aqylt5y\")\n",
    "existing_conversation = json.loads(existing_conversation_json)\n",
    "print(existing_conversation[\"conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messages(conversation):\n",
    "    return [ROLE_CLASS_MAP[message[\"role\"]](content=message[\"content\"]) for message in conversation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Hola, ¿en que puedo ayudarlo?', additional_kwargs={}, response_metadata={}), HumanMessage(content='como se envian los gastos medicos', additional_kwargs={}, response_metadata={}), AIMessage(content='1. Llevar el formulario del seguro al médico o dentista para que llene los datos solicitados, como por ejemplo: el diagnóstico y los procedimientos asociados al diagnóstico.<br>2. En situaciones especiales no es necesario que el formulario sea llenado por el médico, como en el caso de una continuación de un tratamiento o una atención de urgencia.<br>3. Detalles sobre los porcentajes de reembolso según la prestación médica realizada no se especifican en el contexto proporcionado.<br>4. Algunas prestaciones como consultas médicas y exámenes, la cobertura aplica automáticamente por I-med (no siempre, hay que fijarse en el bono), por eso se recomienda siempre andar con el formulario, para solicitar el reembolso en caso de que I-med no lo realice en línea.<br>5. No se especifica cómo se realizan las transferencias de gastos médicos en el contexto proporcionado.', additional_kwargs={}, response_metadata={}), HumanMessage(content='cuale son  porcentajes de reembolso', additional_kwargs={}, response_metadata={}), AIMessage(content=' En el contexto proporcionado, no hay información específica sobre los porcentajes de reembolso que se aplican en este caso. Los porcentajes de reembolso dependen de la prestación médica realizada y están detallados en un documento diferente.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "conversation = create_messages(conversation=existing_conversation[\"conversation\"])\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" La información detallada sobre los porcentajes de reembolso según la prestación médica realizada se encuentra en el documento especificado como 'DATA\\\\\\\\preguntas.txt'.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": conversation,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
